nohup: ignoring input
2022-05-03 20:26:07.289565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
train_data_size: 48687
mode: Both
----------------第0个epoch--------------
0/12171 batch训练完成 Loss: 0.6965581178665161
已用时间 : 0.0分钟。。。。。。。
100/12171 batch训练完成 Loss: 0.32761237025260925
200/12171 batch训练完成 Loss: 0.37421831488609314
300/12171 batch训练完成 Loss: 0.6260620355606079
400/12171 batch训练完成 Loss: 0.320980966091156
500/12171 batch训练完成 Loss: 0.2098315805196762
600/12171 batch训练完成 Loss: 0.1601925641298294
700/12171 batch训练完成 Loss: 0.4196850657463074
800/12171 batch训练完成 Loss: 0.34257227182388306
900/12171 batch训练完成 Loss: 0.08274027705192566
1000/12171 batch训练完成 Loss: 0.3128502070903778
已用时间 : 4.0分钟。。。。。。。
1100/12171 batch训练完成 Loss: 0.09299299120903015
1200/12171 batch训练完成 Loss: 0.3448912799358368
1300/12171 batch训练完成 Loss: 0.29147106409072876
1400/12171 batch训练完成 Loss: 0.6096078753471375
1500/12171 batch训练完成 Loss: 0.15954238176345825
1600/12171 batch训练完成 Loss: 0.1326826810836792
1700/12171 batch训练完成 Loss: 0.043243441730737686
1800/12171 batch训练完成 Loss: 0.7844523191452026
1900/12171 batch训练完成 Loss: 0.4369926154613495
2000/12171 batch训练完成 Loss: 0.47667375206947327
已用时间 : 9.0分钟。。。。。。。
2100/12171 batch训练完成 Loss: 0.03979074954986572
2200/12171 batch训练完成 Loss: 0.17955830693244934
2300/12171 batch训练完成 Loss: 0.0849297046661377
2400/12171 batch训练完成 Loss: 0.22440916299819946
2500/12171 batch训练完成 Loss: 0.3067636489868164
2600/12171 batch训练完成 Loss: 0.3847348093986511
2700/12171 batch训练完成 Loss: 0.08891028165817261
2800/12171 batch训练完成 Loss: 0.12952248752117157
2900/12171 batch训练完成 Loss: 1.4609251022338867
3000/12171 batch训练完成 Loss: 0.4333553910255432
已用时间 : 14.0分钟。。。。。。。
3100/12171 batch训练完成 Loss: 0.17821171879768372
3200/12171 batch训练完成 Loss: 0.4730150103569031
3300/12171 batch训练完成 Loss: 0.08730847388505936
3400/12171 batch训练完成 Loss: 1.0478862524032593
3500/12171 batch训练完成 Loss: 0.3878306746482849
3600/12171 batch训练完成 Loss: 0.141439288854599
3700/12171 batch训练完成 Loss: 0.07612311840057373
3800/12171 batch训练完成 Loss: 0.08167366683483124
3900/12171 batch训练完成 Loss: 0.7605303525924683
4000/12171 batch训练完成 Loss: 0.24478799104690552
已用时间 : 19.0分钟。。。。。。。
4100/12171 batch训练完成 Loss: 0.3510880768299103
4200/12171 batch训练完成 Loss: 0.20036709308624268
4300/12171 batch训练完成 Loss: 0.2689000964164734
4400/12171 batch训练完成 Loss: 0.1529843807220459
4500/12171 batch训练完成 Loss: 0.2725653648376465
4600/12171 batch训练完成 Loss: 0.05252773314714432
4700/12171 batch训练完成 Loss: 0.11632928252220154
4800/12171 batch训练完成 Loss: 0.9424355030059814
4900/12171 batch训练完成 Loss: 0.16943462193012238
5000/12171 batch训练完成 Loss: 0.9569603204727173
已用时间 : 24.0分钟。。。。。。。
5100/12171 batch训练完成 Loss: 0.25386476516723633
5200/12171 batch训练完成 Loss: 0.09728963673114777
5300/12171 batch训练完成 Loss: 0.3605678677558899
5400/12171 batch训练完成 Loss: 0.32033848762512207
5500/12171 batch训练完成 Loss: 0.0862436294555664
5600/12171 batch训练完成 Loss: 0.033873021602630615
5700/12171 batch训练完成 Loss: 0.301956444978714
5800/12171 batch训练完成 Loss: 0.1688971072435379
5900/12171 batch训练完成 Loss: 0.29891204833984375
6000/12171 batch训练完成 Loss: 0.16314612329006195
已用时间 : 29.0分钟。。。。。。。
6100/12171 batch训练完成 Loss: 0.04896802827715874
6200/12171 batch训练完成 Loss: 0.3312147855758667
6300/12171 batch训练完成 Loss: 0.41208159923553467
6400/12171 batch训练完成 Loss: 0.056295596063137054
6500/12171 batch训练完成 Loss: 0.25723356008529663
6600/12171 batch训练完成 Loss: 0.2713978886604309
6700/12171 batch训练完成 Loss: 0.08092564344406128
6800/12171 batch训练完成 Loss: 0.028005234897136688
6900/12171 batch训练完成 Loss: 0.07222435623407364
7000/12171 batch训练完成 Loss: 0.17559444904327393
已用时间 : 33.0分钟。。。。。。。
7100/12171 batch训练完成 Loss: 0.1204359233379364
7200/12171 batch训练完成 Loss: 0.10780300199985504
7300/12171 batch训练完成 Loss: 0.032712649554014206
7400/12171 batch训练完成 Loss: 0.10836604237556458
7500/12171 batch训练完成 Loss: 0.4943395256996155
7600/12171 batch训练完成 Loss: 0.27237969636917114
7700/12171 batch训练完成 Loss: 0.1618460863828659
7800/12171 batch训练完成 Loss: 0.5898010730743408
7900/12171 batch训练完成 Loss: 0.2763153612613678
8000/12171 batch训练完成 Loss: 0.45760905742645264
已用时间 : 38.0分钟。。。。。。。
8100/12171 batch训练完成 Loss: 0.07890161871910095
8200/12171 batch训练完成 Loss: 1.108254075050354
8300/12171 batch训练完成 Loss: 0.09746389836072922
8400/12171 batch训练完成 Loss: 0.5890696048736572
8500/12171 batch训练完成 Loss: 0.9965446591377258
8600/12171 batch训练完成 Loss: 0.2756533920764923
8700/12171 batch训练完成 Loss: 0.3449881076812744
8800/12171 batch训练完成 Loss: 0.015389337204396725
8900/12171 batch训练完成 Loss: 0.38175201416015625
9000/12171 batch训练完成 Loss: 0.04946255311369896
已用时间 : 43.0分钟。。。。。。。
9100/12171 batch训练完成 Loss: 1.2902179956436157
9200/12171 batch训练完成 Loss: 0.22387005388736725
9300/12171 batch训练完成 Loss: 0.1867789626121521
9400/12171 batch训练完成 Loss: 0.03385734558105469
9500/12171 batch训练完成 Loss: 0.18694984912872314
9600/12171 batch训练完成 Loss: 0.0735754445195198
9700/12171 batch训练完成 Loss: 0.06285245716571808
9800/12171 batch训练完成 Loss: 0.0381271168589592
9900/12171 batch训练完成 Loss: 0.08430278301239014
10000/12171 batch训练完成 Loss: 1.915439248085022
已用时间 : 48.0分钟。。。。。。。
10100/12171 batch训练完成 Loss: 0.01183045469224453
10200/12171 batch训练完成 Loss: 0.04253749921917915
10300/12171 batch训练完成 Loss: 0.5157751441001892
10400/12171 batch训练完成 Loss: 0.31990790367126465
10500/12171 batch训练完成 Loss: 0.03864919766783714
10600/12171 batch训练完成 Loss: 0.20463547110557556
10700/12171 batch训练完成 Loss: 0.08961688727140427
10800/12171 batch训练完成 Loss: 0.23105591535568237
10900/12171 batch训练完成 Loss: 0.510220468044281
11000/12171 batch训练完成 Loss: 0.049452539533376694
已用时间 : 53.0分钟。。。。。。。
11100/12171 batch训练完成 Loss: 0.14426322281360626
11200/12171 batch训练完成 Loss: 0.03657524287700653
11300/12171 batch训练完成 Loss: 0.299252986907959
11400/12171 batch训练完成 Loss: 0.5802006125450134
11500/12171 batch训练完成 Loss: 0.012498212046921253
11600/12171 batch训练完成 Loss: 0.1940404623746872
11700/12171 batch训练完成 Loss: 0.13076679408550262
11800/12171 batch训练完成 Loss: 0.08648505806922913
11900/12171 batch训练完成 Loss: 0.009201758541166782
12000/12171 batch训练完成 Loss: 0.08124816417694092
已用时间 : 58.0分钟。。。。。。。
12100/12171 batch训练完成 Loss: 0.09355995059013367
epoch训练次数：0, Loss: 0.07240748405456543
模型保存成功
This is the celeb_syn valid dataset!
dataset size:6086
 
本次epoch的acc为：0.9181728557344726
本次epoch的auc为：0.972749771621546
[[2788  255]
 [ 243 2800]]为本次epoch的混淆矩阵
This is the Dfdc_syn test dataset!
dataset size:965
 
-------本次epoch在DFDC上的acc为：0.8290155440414507
-------本次epoch在DFDC上的auc为：0.9003934606496397
[[430  52]
 [113 370]]为本次epoch的混淆矩阵
----------------第1个epoch--------------
0/12171 batch训练完成 Loss: 0.18439510464668274
已用时间 : 0.0分钟。。。。。。。
100/12171 batch训练完成 Loss: 0.08929897099733353
200/12171 batch训练完成 Loss: 0.12563081085681915
300/12171 batch训练完成 Loss: 0.7015845775604248
400/12171 batch训练完成 Loss: 0.07274346053600311
500/12171 batch训练完成 Loss: 0.5840666890144348
600/12171 batch训练完成 Loss: 0.04283171892166138
700/12171 batch训练完成 Loss: 0.019760319963097572
800/12171 batch训练完成 Loss: 0.038916368037462234
900/12171 batch训练完成 Loss: 0.04536428302526474
1000/12171 batch训练完成 Loss: 0.07469545304775238
已用时间 : 4.0分钟。。。。。。。
1100/12171 batch训练完成 Loss: 0.3667297959327698
1200/12171 batch训练完成 Loss: 0.07598468661308289
1300/12171 batch训练完成 Loss: 0.8587036728858948
1400/12171 batch训练完成 Loss: 0.04006972163915634
1500/12171 batch训练完成 Loss: 0.3265727758407593
1600/12171 batch训练完成 Loss: 0.024116769433021545
1700/12171 batch训练完成 Loss: 0.022256311029195786
1800/12171 batch训练完成 Loss: 0.13259685039520264
1900/12171 batch训练完成 Loss: 0.1406051069498062
2000/12171 batch训练完成 Loss: 0.06065536290407181
已用时间 : 9.0分钟。。。。。。。
2100/12171 batch训练完成 Loss: 0.09882704168558121
2200/12171 batch训练完成 Loss: 0.16964633762836456
2300/12171 batch训练完成 Loss: 0.16434556245803833
2400/12171 batch训练完成 Loss: 0.2919103801250458
2500/12171 batch训练完成 Loss: 0.45804253220558167
2600/12171 batch训练完成 Loss: 0.03228849172592163
2700/12171 batch训练完成 Loss: 0.06445402652025223
2800/12171 batch训练完成 Loss: 0.024174222722649574
2900/12171 batch训练完成 Loss: 0.0745822936296463
3000/12171 batch训练完成 Loss: 0.05725861340761185
已用时间 : 14.0分钟。。。。。。。
3100/12171 batch训练完成 Loss: 0.521729052066803
3200/12171 batch训练完成 Loss: 0.12052279710769653
3300/12171 batch训练完成 Loss: 0.02910739928483963
3400/12171 batch训练完成 Loss: 0.20677122473716736
3500/12171 batch训练完成 Loss: 0.008225527592003345
3600/12171 batch训练完成 Loss: 0.04962648078799248
3700/12171 batch训练完成 Loss: 0.08008452504873276
3800/12171 batch训练完成 Loss: 0.06239372491836548
3900/12171 batch训练完成 Loss: 0.23315167427062988
4000/12171 batch训练完成 Loss: 0.13181322813034058
已用时间 : 19.0分钟。。。。。。。
4100/12171 batch训练完成 Loss: 0.023683007806539536
4200/12171 batch训练完成 Loss: 0.22198761999607086
4300/12171 batch训练完成 Loss: 0.25526028871536255
4400/12171 batch训练完成 Loss: 0.08764330297708511
4500/12171 batch训练完成 Loss: 0.10953857004642487
4600/12171 batch训练完成 Loss: 0.07186385989189148
4700/12171 batch训练完成 Loss: 0.04277930036187172
4800/12171 batch训练完成 Loss: 0.015334767289459705
4900/12171 batch训练完成 Loss: 0.047054633498191833
5000/12171 batch训练完成 Loss: 0.03837147355079651
已用时间 : 23.0分钟。。。。。。。
5100/12171 batch训练完成 Loss: 0.11837510019540787
5200/12171 batch训练完成 Loss: 0.1403817981481552
5300/12171 batch训练完成 Loss: 0.4544006586074829
5400/12171 batch训练完成 Loss: 0.566752552986145
5500/12171 batch训练完成 Loss: 0.04060343652963638
5600/12171 batch训练完成 Loss: 0.07930470257997513
5700/12171 batch训练完成 Loss: 0.1707020401954651
5800/12171 batch训练完成 Loss: 0.065029077231884
5900/12171 batch训练完成 Loss: 0.1362854242324829
6000/12171 batch训练完成 Loss: 0.2643350660800934
已用时间 : 28.0分钟。。。。。。。
6100/12171 batch训练完成 Loss: 0.018002483993768692
6200/12171 batch训练完成 Loss: 0.3791922926902771
6300/12171 batch训练完成 Loss: 0.058655694127082825
6400/12171 batch训练完成 Loss: 0.06316105276346207
6500/12171 batch训练完成 Loss: 0.21329979598522186
6600/12171 batch训练完成 Loss: 0.008673468604683876
6700/12171 batch训练完成 Loss: 0.2372511327266693
6800/12171 batch训练完成 Loss: 0.00613968912512064
6900/12171 batch训练完成 Loss: 0.03179967403411865
7000/12171 batch训练完成 Loss: 0.030910398811101913
已用时间 : 33.0分钟。。。。。。。
7100/12171 batch训练完成 Loss: 0.13775543868541718
7200/12171 batch训练完成 Loss: 0.01454558689147234
7300/12171 batch训练完成 Loss: 0.014251770451664925
7400/12171 batch训练完成 Loss: 0.06507386267185211
7500/12171 batch训练完成 Loss: 0.21334309875965118
7600/12171 batch训练完成 Loss: 0.1294998824596405
7700/12171 batch训练完成 Loss: 0.07763059437274933
7800/12171 batch训练完成 Loss: 0.22365045547485352
7900/12171 batch训练完成 Loss: 0.22801385819911957
8000/12171 batch训练完成 Loss: 0.1949487030506134
已用时间 : 37.0分钟。。。。。。。
8100/12171 batch训练完成 Loss: 0.3066118061542511
8200/12171 batch训练完成 Loss: 0.08091656863689423
8300/12171 batch训练完成 Loss: 0.8881272077560425
8400/12171 batch训练完成 Loss: 0.4542783200740814
8500/12171 batch训练完成 Loss: 0.014336083084344864
8600/12171 batch训练完成 Loss: 0.0351005382835865
8700/12171 batch训练完成 Loss: 0.27163901925086975
8800/12171 batch训练完成 Loss: 1.4373936653137207
8900/12171 batch训练完成 Loss: 0.45635008811950684
9000/12171 batch训练完成 Loss: 0.05253365635871887
已用时间 : 42.0分钟。。。。。。。
9100/12171 batch训练完成 Loss: 0.2524363398551941
9200/12171 batch训练完成 Loss: 0.019110318273305893
9300/12171 batch训练完成 Loss: 0.017940649762749672
9400/12171 batch训练完成 Loss: 0.6279701590538025
9500/12171 batch训练完成 Loss: 0.21071940660476685
9600/12171 batch训练完成 Loss: 0.02890784479677677
9700/12171 batch训练完成 Loss: 0.19384576380252838
9800/12171 batch训练完成 Loss: 0.30792200565338135
9900/12171 batch训练完成 Loss: 0.0671931579709053
10000/12171 batch训练完成 Loss: 0.05335405468940735
已用时间 : 47.0分钟。。。。。。。
10100/12171 batch训练完成 Loss: 0.08182843774557114
10200/12171 batch训练完成 Loss: 0.06834965944290161
10300/12171 batch训练完成 Loss: 0.31886059045791626
10400/12171 batch训练完成 Loss: 0.10390312969684601
10500/12171 batch训练完成 Loss: 0.02254793606698513
10600/12171 batch训练完成 Loss: 0.08751748502254486
10700/12171 batch训练完成 Loss: 0.14267316460609436
10800/12171 batch训练完成 Loss: 0.7840129137039185
10900/12171 batch训练完成 Loss: 0.04538927972316742
11000/12171 batch训练完成 Loss: 0.04488888010382652
已用时间 : 52.0分钟。。。。。。。
11100/12171 batch训练完成 Loss: 0.051943033933639526
11200/12171 batch训练完成 Loss: 0.07178466767072678
11300/12171 batch训练完成 Loss: 0.13936889171600342
11400/12171 batch训练完成 Loss: 0.015571936033666134
11500/12171 batch训练完成 Loss: 0.009948372840881348
11600/12171 batch训练完成 Loss: 1.0363538265228271
11700/12171 batch训练完成 Loss: 0.046897295862436295
11800/12171 batch训练完成 Loss: 0.03650807961821556
11900/12171 batch训练完成 Loss: 0.2317768633365631
12000/12171 batch训练完成 Loss: 0.015034075826406479
已用时间 : 57.0分钟。。。。。。。
12100/12171 batch训练完成 Loss: 0.12770164012908936
epoch训练次数：1, Loss: 0.11604715883731842
This is the celeb_syn valid dataset!
dataset size:6086
 
本次epoch的acc为：0.9227735787052251
本次epoch的auc为：0.976420781807565
[[2752  291]
 [ 179 2864]]为本次epoch的混淆矩阵
This is the Dfdc_syn test dataset!
dataset size:965
 
-------本次epoch在DFDC上的acc为：0.7544041450777202
-------本次epoch在DFDC上的auc为：0.8695738082351829
[[446  36]
 [201 282]]为本次epoch的混淆矩阵
----------------第2个epoch--------------
0/12171 batch训练完成 Loss: 0.07424736022949219
已用时间 : 0.0分钟。。。。。。。
100/12171 batch训练完成 Loss: 0.027500135824084282
200/12171 batch训练完成 Loss: 0.17963847517967224
300/12171 batch训练完成 Loss: 0.3878331482410431
400/12171 batch训练完成 Loss: 0.01964537799358368
500/12171 batch训练完成 Loss: 0.1636674404144287
600/12171 batch训练完成 Loss: 0.006408870220184326
700/12171 batch训练完成 Loss: 1.9896162748336792
800/12171 batch训练完成 Loss: 0.10808615386486053
900/12171 batch训练完成 Loss: 0.016611212864518166
1000/12171 batch训练完成 Loss: 0.41720449924468994
已用时间 : 5.0分钟。。。。。。。
1100/12171 batch训练完成 Loss: 0.07773999124765396
1200/12171 batch训练完成 Loss: 0.07663345336914062
1300/12171 batch训练完成 Loss: 0.18513239920139313
1400/12171 batch训练完成 Loss: 1.5452606678009033
1500/12171 batch训练完成 Loss: 0.02686777338385582
1600/12171 batch训练完成 Loss: 0.4956238269805908
1700/12171 batch训练完成 Loss: 0.08509771525859833
1800/12171 batch训练完成 Loss: 0.4799768924713135
1900/12171 batch训练完成 Loss: 0.5406381487846375
2000/12171 batch训练完成 Loss: 0.18501783907413483
已用时间 : 10.0分钟。。。。。。。
2100/12171 batch训练完成 Loss: 1.1909263134002686
2200/12171 batch训练完成 Loss: 0.3543303608894348
2300/12171 batch训练完成 Loss: 0.05065753310918808
2400/12171 batch训练完成 Loss: 0.4209737479686737
2500/12171 batch训练完成 Loss: 0.0631435364484787
2600/12171 batch训练完成 Loss: 0.09218672662973404
2700/12171 batch训练完成 Loss: 0.055738817900419235
2800/12171 batch训练完成 Loss: 0.00923218671232462
2900/12171 batch训练完成 Loss: 0.09942665696144104
3000/12171 batch训练完成 Loss: 0.08189858496189117
已用时间 : 15.0分钟。。。。。。。
3100/12171 batch训练完成 Loss: 0.03578700125217438
3200/12171 batch训练完成 Loss: 0.07773846387863159
3300/12171 batch训练完成 Loss: 0.07149942964315414
3400/12171 batch训练完成 Loss: 0.2532790005207062
3500/12171 batch训练完成 Loss: 0.06559544056653976
3600/12171 batch训练完成 Loss: 0.10124262422323227
3700/12171 batch训练完成 Loss: 0.021148698404431343
3800/12171 batch训练完成 Loss: 0.26707080006599426
3900/12171 batch训练完成 Loss: 1.2253854274749756
4000/12171 batch训练完成 Loss: 0.5726259350776672
已用时间 : 20.0分钟。。。。。。。
4100/12171 batch训练完成 Loss: 0.2140417844057083
4200/12171 batch训练完成 Loss: 0.21533894538879395
4300/12171 batch训练完成 Loss: 0.008043229579925537
4400/12171 batch训练完成 Loss: 0.021891936659812927
4500/12171 batch训练完成 Loss: 1.3088428974151611
4600/12171 batch训练完成 Loss: 0.22594058513641357
4700/12171 batch训练完成 Loss: 0.009747471660375595
4800/12171 batch训练完成 Loss: 1.1303489208221436
4900/12171 batch训练完成 Loss: 0.018601084128022194
5000/12171 batch训练完成 Loss: 0.8725178241729736
已用时间 : 26.0分钟。。。。。。。
5100/12171 batch训练完成 Loss: 0.3421904742717743
5200/12171 batch训练完成 Loss: 0.3592807948589325
5300/12171 batch训练完成 Loss: 0.17563016712665558
5400/12171 batch训练完成 Loss: 0.06850172579288483
5500/12171 batch训练完成 Loss: 0.12067019939422607
5600/12171 batch训练完成 Loss: 0.18747565150260925
5700/12171 batch训练完成 Loss: 0.04628582298755646
5800/12171 batch训练完成 Loss: 0.08460190147161484
5900/12171 batch训练完成 Loss: 1.0878328084945679
6000/12171 batch训练完成 Loss: 0.19087471067905426
已用时间 : 31.0分钟。。。。。。。
6100/12171 batch训练完成 Loss: 0.01080091018229723
6200/12171 batch训练完成 Loss: 0.043079912662506104
6300/12171 batch训练完成 Loss: 0.1215135008096695
6400/12171 batch训练完成 Loss: 0.03437188267707825
6500/12171 batch训练完成 Loss: 0.4504855275154114
6600/12171 batch训练完成 Loss: 0.05736381560564041
6700/12171 batch训练完成 Loss: 0.3496577739715576
6800/12171 batch训练完成 Loss: 0.1461068093776703
6900/12171 batch训练完成 Loss: 0.7747544050216675
7000/12171 batch训练完成 Loss: 0.291424423456192
已用时间 : 36.0分钟。。。。。。。
7100/12171 batch训练完成 Loss: 0.1829163283109665
7200/12171 batch训练完成 Loss: 0.035000480711460114
7300/12171 batch训练完成 Loss: 0.1505945473909378
7400/12171 batch训练完成 Loss: 0.045788444578647614
7500/12171 batch训练完成 Loss: 0.21952587366104126
7600/12171 batch训练完成 Loss: 0.7803840041160583
7700/12171 batch训练完成 Loss: 0.13509824872016907
7800/12171 batch训练完成 Loss: 0.02420039474964142
7900/12171 batch训练完成 Loss: 0.06483763456344604
8000/12171 batch训练完成 Loss: 0.10998719185590744
已用时间 : 42.0分钟。。。。。。。
8100/12171 batch训练完成 Loss: 0.6363418102264404
8200/12171 batch训练完成 Loss: 0.042689353227615356
8300/12171 batch训练完成 Loss: 0.5211309194564819
8400/12171 batch训练完成 Loss: 0.032941315323114395
8500/12171 batch训练完成 Loss: 0.03652239218354225
8600/12171 batch训练完成 Loss: 0.015501759946346283
8700/12171 batch训练完成 Loss: 0.020084228366613388
8800/12171 batch训练完成 Loss: 0.09277618676424026
8900/12171 batch训练完成 Loss: 0.11615265160799026
9000/12171 batch训练完成 Loss: 0.07018669694662094
已用时间 : 47.0分钟。。。。。。。
9100/12171 batch训练完成 Loss: 0.4488717317581177
9200/12171 batch训练完成 Loss: 0.030869098380208015
9300/12171 batch训练完成 Loss: 0.025569558143615723
9400/12171 batch训练完成 Loss: 0.3668733537197113
9500/12171 batch训练完成 Loss: 0.013657016679644585
9600/12171 batch训练完成 Loss: 0.043650396168231964
9700/12171 batch训练完成 Loss: 0.4019680619239807
9800/12171 batch训练完成 Loss: 0.05113935098052025
9900/12171 batch训练完成 Loss: 0.06212544068694115
10000/12171 batch训练完成 Loss: 0.07620766758918762
已用时间 : 52.0分钟。。。。。。。
10100/12171 batch训练完成 Loss: 1.4228129386901855
10200/12171 batch训练完成 Loss: 0.06538393348455429
10300/12171 batch训练完成 Loss: 0.06752344220876694
10400/12171 batch训练完成 Loss: 0.22401809692382812
10500/12171 batch训练完成 Loss: 0.2259073555469513
10600/12171 batch训练完成 Loss: 0.12965670228004456
10700/12171 batch训练完成 Loss: 0.22366292774677277
10800/12171 batch训练完成 Loss: 0.030744850635528564
10900/12171 batch训练完成 Loss: 0.019865427166223526
11000/12171 batch训练完成 Loss: 0.27121269702911377
已用时间 : 57.0分钟。。。。。。。
11100/12171 batch训练完成 Loss: 0.1676604151725769
11200/12171 batch训练完成 Loss: 0.21856865286827087
11300/12171 batch训练完成 Loss: 0.0521756187081337
11400/12171 batch训练完成 Loss: 0.36787259578704834
11500/12171 batch训练完成 Loss: 0.01132113952189684
11600/12171 batch训练完成 Loss: 0.10380654036998749
11700/12171 batch训练完成 Loss: 0.1420818716287613
11800/12171 batch训练完成 Loss: 0.551605761051178
11900/12171 batch训练完成 Loss: 0.03842907398939133
12000/12171 batch训练完成 Loss: 0.288640558719635
已用时间 : 63.0分钟。。。。。。。
12100/12171 batch训练完成 Loss: 0.0780470222234726
epoch训练次数：2, Loss: 0.007345686666667461
This is the celeb_syn valid dataset!
dataset size:6086
 
本次epoch的acc为：0.9040420637528754
本次epoch的auc为：0.9725675872252344
[[2601  442]
 [ 142 2901]]为本次epoch的混淆矩阵
This is the Dfdc_syn test dataset!
dataset size:965
 
-------本次epoch在DFDC上的acc为：0.7979274611398963
-------本次epoch在DFDC上的auc为：0.8842899237992148
[[427  55]
 [140 343]]为本次epoch的混淆矩阵
----------------第3个epoch--------------
0/12171 batch训练完成 Loss: 0.030375633388757706
已用时间 : 0.0分钟。。。。。。。
100/12171 batch训练完成 Loss: 0.6023516654968262
200/12171 batch训练完成 Loss: 0.28915685415267944
300/12171 batch训练完成 Loss: 0.4110427796840668
400/12171 batch训练完成 Loss: 0.09583184123039246
500/12171 batch训练完成 Loss: 0.0682159811258316
600/12171 batch训练完成 Loss: 0.06895268708467484
700/12171 batch训练完成 Loss: 0.0647960901260376
800/12171 batch训练完成 Loss: 0.36126840114593506
900/12171 batch训练完成 Loss: 0.023007776588201523
1000/12171 batch训练完成 Loss: 0.5222033262252808
已用时间 : 5.0分钟。。。。。。。
1100/12171 batch训练完成 Loss: 0.0160733200609684
1200/12171 batch训练完成 Loss: 0.045982781797647476
1300/12171 batch训练完成 Loss: 0.08319705724716187
1400/12171 batch训练完成 Loss: 0.02048024721443653
1500/12171 batch训练完成 Loss: 0.29033422470092773
1600/12171 batch训练完成 Loss: 0.0066799442283809185
1700/12171 batch训练完成 Loss: 0.17482557892799377
1800/12171 batch训练完成 Loss: 0.3052009642124176
1900/12171 batch训练完成 Loss: 0.050793010741472244
2000/12171 batch训练完成 Loss: 0.05469629913568497
已用时间 : 10.0分钟。。。。。。。
2100/12171 batch训练完成 Loss: 0.5811705589294434
2200/12171 batch训练完成 Loss: 0.027813797816634178
2300/12171 batch训练完成 Loss: 0.044770415872335434
2400/12171 batch训练完成 Loss: 0.02914794348180294
2500/12171 batch训练完成 Loss: 0.020983591675758362
2600/12171 batch训练完成 Loss: 0.03008083626627922
2700/12171 batch训练完成 Loss: 0.2598453164100647
2800/12171 batch训练完成 Loss: 0.054882075637578964
2900/12171 batch训练完成 Loss: 0.061942629516124725
3000/12171 batch训练完成 Loss: 0.01992279663681984
已用时间 : 15.0分钟。。。。。。。
3100/12171 batch训练完成 Loss: 0.43540048599243164
3200/12171 batch训练完成 Loss: 0.02070767432451248
3300/12171 batch训练完成 Loss: 0.4082428812980652
3400/12171 batch训练完成 Loss: 0.021532900631427765
3500/12171 batch训练完成 Loss: 0.316366970539093
3600/12171 batch训练完成 Loss: 0.35369181632995605
3700/12171 batch训练完成 Loss: 0.003195782657712698
3800/12171 batch训练完成 Loss: 0.055790726095438004
3900/12171 batch训练完成 Loss: 0.218770831823349
4000/12171 batch训练完成 Loss: 0.019664224237203598
已用时间 : 20.0分钟。。。。。。。
4100/12171 batch训练完成 Loss: 0.029223725199699402
4200/12171 batch训练完成 Loss: 0.2788444459438324
4300/12171 batch训练完成 Loss: 0.07468285411596298
4400/12171 batch训练完成 Loss: 0.09343159198760986
4500/12171 batch训练完成 Loss: 0.004454074893146753
4600/12171 batch训练完成 Loss: 0.4027937054634094
4700/12171 batch训练完成 Loss: 0.07659406214952469
4800/12171 batch训练完成 Loss: 0.016557469964027405
4900/12171 batch训练完成 Loss: 0.05795431509613991
5000/12171 batch训练完成 Loss: 0.040199197828769684
已用时间 : 25.0分钟。。。。。。。
5100/12171 batch训练完成 Loss: 0.036826618015766144
5200/12171 batch训练完成 Loss: 0.037685930728912354
5300/12171 batch训练完成 Loss: 0.05594499036669731
5400/12171 batch训练完成 Loss: 0.11970284581184387
